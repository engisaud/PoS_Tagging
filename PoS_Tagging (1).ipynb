{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries\n"
      ],
      "metadata": {
        "id": "y1xXL2jdBdff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "_IZay8W4Bgp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download necessary resources\n"
      ],
      "metadata": {
        "id": "C8dvIUnhBhjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "ZUzaKoa_BjEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431d2777-4abf-43f4-b86f-8b6b418f45eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence\n"
      ],
      "metadata": {
        "id": "EWP_F1sYBkEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "OkTzhGvsBldA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Tokenize the sentence\n",
        "# Tokenization is the process of breaking down the text into individual words or tokens."
      ],
      "metadata": {
        "id": "dJA1CBrMBl5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(sentence)\n",
        "print(\"Tokenized Words:\", words)"
      ],
      "metadata": {
        "id": "lz4mtx9oBq2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea21771-1cd9-4506-aa2f-8fb016bbd787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Perform Part of Speech (PoS) tagging\n",
        "# PoS tagging assigns a part of speech to each word (e.g., noun, verb, adjective)."
      ],
      "metadata": {
        "id": "zVaGjcGwBsuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(words)\n",
        "print(\"\\nPoS Tagged Words:\", tagged_words)"
      ],
      "metadata": {
        "id": "i7SZQIfEBuQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8242aa2-b6f8-4c79-8d68-ebae2b3b6845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Tagged Words: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "The output of pos_tag is a list of tuples, where each tuple contains a word and its corresponding PoS tag.\n",
        "Common PoS tags include:\n",
        " - NN: Noun\n",
        " - VB: Verb\n",
        " - JJ: Adjective\n",
        " - RB: Adverb\n",
        " - IN: Preposition"
      ],
      "metadata": {
        "id": "jgToAf0GByEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Extract specific parts of speech\n",
        " Let's extract all nouns (NN) from the tagged words."
      ],
      "metadata": {
        "id": "FG1YwXy7B8de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = [word for word, pos in tagged_words if pos == 'NN']\n",
        "print(\"\\nNouns:\", nouns)"
      ],
      "metadata": {
        "id": "zzxtRMP1B94s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34ad72c-ba13-41e8-8f05-c57a66ce7d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nouns: ['brown', 'fox', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Count the occurrences of each PoS tag\n",
        "We can use a Counter to count how many times each PoS tag appears in the sentence."
      ],
      "metadata": {
        "id": "zwoKuYF2CAnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "pos_counts = Counter([pos for word, pos in tagged_words])\n",
        "print(\"\\nPoS Counts:\", pos_counts)"
      ],
      "metadata": {
        "id": "NTvpb5MxCCz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033cfdd8-cd5e-48e8-d89f-5d3ecab1754f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Counts: Counter({'NN': 3, 'DT': 2, 'JJ': 2, 'VBZ': 1, 'IN': 1, '.': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Extract all verbs from the sentence\n",
        "Verbs can have different tags like VB, VBD (past tense), VBG (gerund), etc."
      ],
      "metadata": {
        "id": "W__OyoOXCEsD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke_HUhQLAc_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfc845d-48e0-45df-bdec-b2992bc0b494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verbs: ['jumps']\n"
          ]
        }
      ],
      "source": [
        "verbs = [word for word, pos in tagged_words if pos.startswith('VB')]\n",
        "print(\"\\nVerbs:\", verbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary modules\n"
      ],
      "metadata": {
        "id": "nJ_k6hE8CZr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n"
      ],
      "metadata": {
        "id": "J34LLTqACaFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence\n"
      ],
      "metadata": {
        "id": "0UGjpQb9CbGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "-PxjEVcnCdWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Tokenize the sentence and perform PoS tagging\n"
      ],
      "metadata": {
        "id": "Z5QsOidjCeRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(word_tokenize(sentence))"
      ],
      "metadata": {
        "id": "_MUmEuzHCfZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Extract only the nouns (NN) from the tagged words\n"
      ],
      "metadata": {
        "id": "xeS1f0hnCiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we add this command word for word, tag in tagged_words if tag.startswith('NN')\n",
        "nouns = [word for word, tag in tagged_words if tag.startswith('NN')]\n",
        "print(\"Nouns:\", nouns)"
      ],
      "metadata": {
        "id": "Jo29Q_XNCVw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833578e2-1b34-4c9a-e062-7e8a823965eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns: ['brown', 'fox', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary modules\n"
      ],
      "metadata": {
        "id": "m7-jj2BLClGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "QrutpKbmCmZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence"
      ],
      "metadata": {
        "id": "Y814v2cECm1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "bAotCj-TCqCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Tokenize the sentence and perform PoS tagging\n"
      ],
      "metadata": {
        "id": "KMGD0NHSCsSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(word_tokenize(sentence))\n"
      ],
      "metadata": {
        "id": "KnffHvfxCtRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Count the occurrences of each PoS tag"
      ],
      "metadata": {
        "id": "fnVaIBJcCyhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we add the command == [pos for word, pos in tagged_words]\n",
        "pos_counts = Counter([pos for word, pos in tagged_words])\n",
        "print(\"PoS Counts:\", pos_counts)"
      ],
      "metadata": {
        "id": "JuTLsdYiCWS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6981ca6-d712-4117-93c0-809e10a81b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PoS Counts: Counter({'NN': 3, 'DT': 2, 'JJ': 2, 'VBZ': 1, 'IN': 1, '.': 1})\n"
          ]
        }
      ]
    }
  ]
}